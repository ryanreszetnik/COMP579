{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# COMP 579: Assignment 3\n",
    "March 19th, 2024\n",
    "Group 86:\n",
    "- Mathieu Geoffroy 260986559\n",
    "- Ryan Reszetnik 260948454"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfb514261acb7de6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Value-based methods with linear function approximation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629507c78c8a34ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Setup Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "425a3f3021fcb387"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T16:17:09.261080Z",
     "start_time": "2024-03-13T16:17:08.689152Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mtn_car = gym.make('MountainCar-v0')\n",
    "cart_pole = gym.make('CartPole-v1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T16:17:20.512511Z",
     "start_time": "2024-03-13T16:17:20.509311Z"
    }
   },
   "id": "58372cca72d8ed9e",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Q-learning with linear function approximation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "410f4d738ac91695"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "218b5cc9486ebe1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Expected SARSA with linear function approximation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a57ac79582f5f81e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff584e0fe4567d91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Policy Gradient Theorem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "631e5180a5ac3941"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bab03b8fb6150e2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Policy-based methods with linear function approximation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd2e684cd9e6e268"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b992bdf61aa874a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
